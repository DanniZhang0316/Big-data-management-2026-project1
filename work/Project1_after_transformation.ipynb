{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddf52a31",
   "metadata": {},
   "source": [
    "# NYC Taxi ETL - Incremental Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fe62039",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import IntegerType, DoubleType, StringType\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9796679",
   "metadata": {},
   "outputs": [],
   "source": [
    "INBOX_PATH = Path(\"data/inbox\")\n",
    "STATE_DIR = Path(\"state\")\n",
    "MANIFEST_PATH = STATE_DIR / \"manifest.json\"\n",
    "\n",
    "STATE_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aeb33216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark session initialized: 4.1.0\n"
     ]
    }
   ],
   "source": [
    "# Initialize Spark Session\n",
    "spark = (SparkSession.builder\n",
    "    .appName(\"NYC_Taxi_Incremental_Ingestion\")\n",
    "    .master(\"local[*]\")\n",
    "    .getOrCreate())\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"WARN\")\n",
    "print(f\"Spark session initialized: {spark.version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "197e2eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manifest functions defined\n"
     ]
    }
   ],
   "source": [
    "# Manifest management functions\n",
    "def load_manifest():\n",
    "    \"\"\"Load the manifest tracking processed files.\"\"\"\n",
    "    if MANIFEST_PATH.exists():\n",
    "        try:\n",
    "            with open(MANIFEST_PATH, 'r') as f:\n",
    "                manifest = json.load(f)\n",
    "\n",
    "            if \"processed_files\" not in manifest:\n",
    "                manifest[\"processed_files\"] = []\n",
    "            if \"last_run\" not in manifest:\n",
    "                manifest[\"last_run\"] = None\n",
    "            return manifest\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Warning: Manifest file corrupted, creating new manifest. Error: {e}\")\n",
    "            return {\"processed_files\": [], \"last_run\": None}\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading manifest: {e}\")\n",
    "            raise\n",
    "    return {\"processed_files\": [], \"last_run\": None}\n",
    "\n",
    "def save_manifest(manifest):\n",
    "    \"\"\"Save the manifest to disk.\"\"\"\n",
    "    try:\n",
    "        manifest[\"last_run\"] = datetime.now().isoformat()\n",
    "        with open(MANIFEST_PATH, 'w') as f:\n",
    "            json.dump(manifest, indent=2, fp=f)\n",
    "        print(f\"Manifest saved: {len(manifest['processed_files'])} files tracked\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving manifest: {e}\")\n",
    "        raise\n",
    "\n",
    "def add_to_manifest(manifest, file_info):\n",
    "    \"\"\"Add a processed file to the manifest.\"\"\"\n",
    "    manifest[\"processed_files\"].append(file_info)\n",
    "\n",
    "print(\"Manifest functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edc8e6be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parquet files found in inbox: 3\n",
      "Manifest loaded\n",
      "  - Previously processed: 0 files\n",
      "  - New files found: 2 files\n",
      "    → yellow_tripdata_2025-01.parquet (59,158,238 bytes)\n",
      "    → yellow_tripdata_2025-02.parquet (60,343,086 bytes)\n"
     ]
    }
   ],
   "source": [
    "# Detect new\n",
    "def get_new_files(inbox_path, manifest):\n",
    "    \"\"\"Identify files in inbox that haven't been processed yet.\"\"\"\n",
    "    inbox_path = Path(inbox_path)\n",
    "\n",
    "    if not inbox_path.exists():\n",
    "        raise FileNotFoundError(f\"Inbox path does not exist: {inbox_path}\")\n",
    "\n",
    "    processed_filenames = {f[\"filename\"] for f in manifest[\"processed_files\"]}\n",
    "\n",
    "    all_parquet = sorted(inbox_path.glob(\"*.parquet\"))\n",
    "    print(f\"Parquet files found in inbox: {len(all_parquet)}\")\n",
    "\n",
    "    inbox_files = []\n",
    "    for file in all_parquet:\n",
    "        if \"zone_lookup\" in file.name: # for ignoring the zone lookup\n",
    "            continue\n",
    "\n",
    "        if file.name not in processed_filenames:\n",
    "            file_stat = file.stat()\n",
    "            inbox_files.append({\n",
    "                \"filename\": file.name,\n",
    "                \"path\": str(file),\n",
    "                \"size_bytes\": file_stat.st_size\n",
    "            })\n",
    "\n",
    "    return inbox_files\n",
    "\n",
    "manifest = load_manifest()\n",
    "new_files = get_new_files(INBOX_PATH, manifest)\n",
    "\n",
    "print(\"Manifest loaded\")\n",
    "print(f\"  - Previously processed: {len(manifest['processed_files'])} files\")\n",
    "print(f\"  - New files found: {len(new_files)} files\")\n",
    "if new_files:\n",
    "    for f in new_files:\n",
    "        print(f\"    → {f['filename']} ({f['size_bytes']:,} bytes)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0056a206",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 2 new file(s)...\n",
      "Processing: yellow_tripdata_2025-01.parquet\n",
      "  Rows: 3,475,226\n",
      "  After Cleaning Rows: 2,841,031\n",
      "  After dedup Rows: 2,841,031\n",
      "  Size: 59,158,238 bytes\n",
      "Added to manifest\n",
      "Processing: yellow_tripdata_2025-02.parquet\n",
      "  Rows: 3,577,543\n",
      "  After Cleaning Rows: 2,682,815\n",
      "  After dedup Rows: 2,682,815\n",
      "  Size: 60,343,086 bytes\n",
      "Added to manifest\n",
      "Manifest saved: 2 files tracked\n",
      "Processing complete!\n"
     ]
    }
   ],
   "source": [
    "# Process new files and update manifest\n",
    "if len(new_files) == 0:\n",
    "    print(\"No new files to process.\")\n",
    "else:\n",
    "    print(f\"Processing {len(new_files)} new file(s)...\")\n",
    "    \n",
    "    all_dataframes = []\n",
    "    \n",
    "    for file_info in new_files:\n",
    "        print(f\"Processing: {file_info['filename']}\")\n",
    "        \n",
    "        df = spark.read.parquet(file_info['path'])\n",
    "        row_count = df.count()\n",
    "        \n",
    "        # Parse and cast types correctly\n",
    "        df = (\n",
    "            df\n",
    "            .withColumn(\"VendorID\", F.col(\"VendorID\").cast(IntegerType()))\n",
    "            .withColumn(\"tpep_pickup_datetime\", F.to_timestamp(\"tpep_pickup_datetime\"))\n",
    "            .withColumn(\"tpep_dropoff_datetime\", F.to_timestamp(\"tpep_dropoff_datetime\"))\n",
    "            .withColumn(\"passenger_count\", F.col(\"passenger_count\").cast(IntegerType()))\n",
    "            .withColumn(\"trip_distance\", F.col(\"trip_distance\").cast(DoubleType()))\n",
    "            .withColumn(\"RatecodeID\", F.col(\"RatecodeID\").cast(IntegerType()))\n",
    "            .withColumn(\"store_and_fwd_flag\", F.col(\"store_and_fwd_flag\").cast(StringType()))\n",
    "            .withColumn(\"PULocationID\", F.col(\"PULocationID\").cast(IntegerType()))\n",
    "            .withColumn(\"DOLocationID\", F.col(\"DOLocationID\").cast(IntegerType()))\n",
    "            .withColumn(\"payment_type\", F.col(\"payment_type\").cast(IntegerType()))\n",
    "            .withColumn(\"fare_amount\", F.col(\"fare_amount\").cast(DoubleType()))\n",
    "            .withColumn(\"extra\", F.col(\"extra\").cast(DoubleType()))\n",
    "            .withColumn(\"mta_tax\", F.col(\"mta_tax\").cast(DoubleType()))\n",
    "            .withColumn(\"tip_amount\", F.col(\"tip_amount\").cast(DoubleType()))\n",
    "            .withColumn(\"tolls_amount\", F.col(\"tolls_amount\").cast(DoubleType()))\n",
    "            .withColumn(\"improvement_surcharge\", F.col(\"improvement_surcharge\").cast(DoubleType()))\n",
    "            .withColumn(\"total_amount\", F.col(\"total_amount\").cast(DoubleType()))\n",
    "            .withColumn(\"congestion_surcharge\", F.col(\"congestion_surcharge\").cast(DoubleType()))\n",
    "            .withColumn(\"Airport_fee\", F.col(\"Airport_fee\").cast(DoubleType()))\n",
    "            .withColumn(\"cbd_congestion_fee\", F.col(\"cbd_congestion_fee\").cast(DoubleType()))\n",
    "        )\n",
    "        # Apply data cleaning rules\n",
    "        df = df.filter(\n",
    "            F.col(\"tpep_pickup_datetime\").isNotNull() &\n",
    "            F.col(\"tpep_dropoff_datetime\").isNotNull() &\n",
    "            (F.col(\"tpep_dropoff_datetime\") >= F.col(\"tpep_pickup_datetime\")) &\n",
    "            F.col(\"trip_distance\").isNotNull() & (F.col(\"trip_distance\") > 0) &\n",
    "            F.col(\"passenger_count\").isNotNull() & F.col(\"passenger_count\").between(0, 8) &\n",
    "            F.col(\"PULocationID\").isNotNull() & F.col(\"DOLocationID\").isNotNull()\n",
    "        )\n",
    "        # Money related cols should be >=0\n",
    "        money_related_cols = [\n",
    "            \"extra\",\"mta_tax\",\"tip_amount\",\"tolls_amount\",\n",
    "            \"improvement_surcharge\",\"congestion_surcharge\",\n",
    "            \"Airport_fee\",\"cbd_congestion_fee\"\n",
    "        ]\n",
    "        \n",
    "        for money in money_related_cols:\n",
    "            df = df.withColumn(money, F.coalesce(F.col(money), F.lit(0.0)))\n",
    "            df = df.filter(F.col(money) >= 0)\n",
    "\n",
    "\n",
    "        df = df.withColumn(\"fare_amount\", F.coalesce(F.col(\"fare_amount\"), F.lit(0.0)))\n",
    "\n",
    "        # Only total amount can not be null\n",
    "        df = df.filter(\n",
    "            F.col(\"total_amount\").isNotNull() &\n",
    "            (F.col(\"total_amount\") >= 0)\n",
    "        )\n",
    "        new_row_count = df.count()\n",
    "        \n",
    "        # Deduplicate records using a defined key\n",
    "        dedup_key = [\n",
    "            \"VendorID\",\n",
    "            \"tpep_pickup_datetime\",\n",
    "            \"tpep_dropoff_datetime\",\n",
    "            \"PULocationID\",\n",
    "            \"DOLocationID\",\n",
    "            \"trip_distance\",\n",
    "            \"total_amount\",\n",
    "        ]\n",
    "        df = df.dropDuplicates(dedup_key)\n",
    "\n",
    "        after_dedup_row_count = df.count()\n",
    "\n",
    "        print(f\"  Rows: {row_count:,}\")\n",
    "        print(f\"  After Cleaning Rows: {new_row_count:,}\")\n",
    "        print(f\"  After dedup Rows: {after_dedup_row_count:,}\")\n",
    "        print(f\"  Size: {file_info['size_bytes']:,} bytes\")\n",
    "\n",
    "        ingested_at_value = datetime.now().isoformat()\n",
    "\n",
    "        df = (\n",
    "            df\n",
    "            .withColumn(\"trip_duration_minutes\", (F.unix_timestamp(\"tpep_dropoff_datetime\") - F.unix_timestamp(\"tpep_pickup_datetime\")) / 60.0)\n",
    "            .withColumn(\"pickup_date\", F.to_date(\"tpep_pickup_datetime\"))\n",
    "            .withColumn(\"source_file\", F.lit(file_info[\"filename\"]))\n",
    "            .withColumn(\"ingested_at\", F.lit(ingested_at_value))\n",
    "        )\n",
    "\n",
    "        all_dataframes.append(df)\n",
    "\n",
    "        file_metadata = {\n",
    "            \"filename\": file_info['filename'],\n",
    "            \"size_bytes\": file_info['size_bytes'],\n",
    "            \"raw_row_count\": row_count,\n",
    "            \"clean_row_count\": new_row_count,\n",
    "            \"processed_at\": datetime.now().isoformat()\n",
    "        }\n",
    "        add_to_manifest(manifest, file_metadata)\n",
    "        \n",
    "        print(f\"Added to manifest\")\n",
    "    \n",
    "    save_manifest(manifest)\n",
    "    \n",
    "    print(\"Processing complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5dbedeee-182c-45d4-9cf0-50526044af37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enriching files\n",
      "Final row count: 8767942\n",
      "Wrote enriched dataset to: data/outbox/trips_enriched.parquet\n"
     ]
    }
   ],
   "source": [
    "OUTBOX_PATH = Path(\"data/outbox\")\n",
    "OUT_PATH = OUTBOX_PATH / \"trips_enriched.parquet\"\n",
    "LOOKUP_PATH = INBOX_PATH / \"taxi_zone_lookup.parquet\"\n",
    "OUTBOX_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if len(new_files) == 0:\n",
    "    print(\"No new cleaned dataframes to enrich\")\n",
    "else:\n",
    "    print(\"Enriching files\")\n",
    "    trips_new = reduce(lambda a, b: a.unionByName(b, allowMissingColumns=True), \n",
    "                       all_dataframes)\n",
    "\n",
    "    zones = (spark.read.parquet(str(LOOKUP_PATH)).select(\"LocationID\", \"Zone\"))\n",
    "\n",
    "    zones = F.broadcast(zones)\n",
    "\n",
    "    pu = zones.select(\n",
    "        F.col(\"LocationID\").alias(\"PULocationID\"),\n",
    "        F.col(\"Zone\").alias(\"PU_Zone\"),\n",
    "    )\n",
    "    do = zones.select(\n",
    "        F.col(\"LocationID\").alias(\"DOLocationID\"),\n",
    "        F.col(\"Zone\").alias(\"DO_Zone\"),\n",
    "    )\n",
    "\n",
    "    trips_enriched_new = (\n",
    "        trips_new\n",
    "        .join(pu, on=\"PULocationID\", how=\"left\")\n",
    "        .join(do, on=\"DOLocationID\", how=\"left\")\n",
    "    )\n",
    "\n",
    "    required_cols = [\n",
    "        \"tpep_pickup_datetime\",\n",
    "        \"tpep_dropoff_datetime\",\n",
    "        \"PULocationID\",\n",
    "        \"DOLocationID\",\n",
    "        \"PU_Zone\",\n",
    "        \"DO_Zone\",\n",
    "        \"passenger_count\",\n",
    "        \"trip_distance\",\n",
    "        \"trip_duration_minutes\",\n",
    "        \"pickup_date\",\n",
    "        \"source_file\",\n",
    "        \"ingested_at\",\n",
    "        \"fare_amount\"\n",
    "    ]\n",
    "    trips_enriched_new = trips_enriched_new.select(*required_cols)\n",
    "\n",
    "    # If we already have output data, load it and add the new trips to it\n",
    "    if OUT_PATH.exists():\n",
    "        trips_prev = spark.read.parquet(str(OUT_PATH))\n",
    "        trips_all = trips_prev.unionByName(trips_enriched_new, allowMissingColumns=True)\n",
    "    else:\n",
    "        trips_all = trips_enriched_new\n",
    "    \n",
    "    trips_all = trips_all.cache()\n",
    "    row_c = trips_all.count()\n",
    "    trips_all.write.mode(\"overwrite\").parquet(str(OUT_PATH))\n",
    "    print(\"Final row count:\", row_c)\n",
    "    print(f\"Wrote enriched dataset to: {OUT_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36b61155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Custom Scenario: Flagging Suspicious Trips ---\n",
      "Total trips: 14,291,788\n",
      "Suspicious trips found: 11,288\n",
      "Percentage: 0.08%\n"
     ]
    },
    {
     "ename": "ConnectionRefusedError",
     "evalue": "[Errno 111] Connection refused",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mPy4JNetworkError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/spark/python/lib/py4j-0.10.9.9-src.zip/py4j/java_gateway.py:1038\u001b[39m, in \u001b[36mGatewayClient.send_command\u001b[39m\u001b[34m(self, command, retry, binary)\u001b[39m\n\u001b[32m   1037\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1038\u001b[39m     response = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1039\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m binary:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/spark/python/lib/py4j-0.10.9.9-src.zip/py4j/clientserver.py:540\u001b[39m, in \u001b[36mClientServerConnection.send_command\u001b[39m\u001b[34m(self, command)\u001b[39m\n\u001b[32m    539\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m answer.strip() == \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m540\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JNetworkError(\n\u001b[32m    541\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAnswer from Java side is empty\u001b[39m\u001b[33m\"\u001b[39m, when=proto.EMPTY_RESPONSE)\n\u001b[32m    542\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m answer.startswith(proto.RETURN_MESSAGE):\n",
      "\u001b[31mPy4JNetworkError\u001b[39m: Answer from Java side is empty",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mConnectionRefusedError\u001b[39m                    Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m total_trips > \u001b[32m0\u001b[39m:\n\u001b[32m     21\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPercentage: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msuspicious_count/total_trips*\u001b[32m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m%\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[43mtrips_with_suspicious\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43moverwrite\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparquet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mOUT_PATH\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m✓ Main output (with is_suspicious flag) written to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mOUT_PATH\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     26\u001b[39m SUSPICIOUS_PATH = OUTBOX_PATH / \u001b[33m\"\u001b[39m\u001b[33msuspicious_trips.parquet\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/spark/python/pyspark/sql/readwriter.py:2003\u001b[39m, in \u001b[36mDataFrameWriter.parquet\u001b[39m\u001b[34m(self, path, mode, partitionBy, compression)\u001b[39m\n\u001b[32m   2001\u001b[39m     \u001b[38;5;28mself\u001b[39m.partitionBy(partitionBy)\n\u001b[32m   2002\u001b[39m \u001b[38;5;28mself\u001b[39m._set_opts(compression=compression)\n\u001b[32m-> \u001b[39m\u001b[32m2003\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_jwrite\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/spark/python/lib/py4j-0.10.9.9-src.zip/py4j/java_gateway.py:1361\u001b[39m, in \u001b[36mJavaMember.__call__\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m   1354\u001b[39m args_command, temp_args = \u001b[38;5;28mself\u001b[39m._build_args(*args)\n\u001b[32m   1356\u001b[39m command = proto.CALL_COMMAND_NAME +\\\n\u001b[32m   1357\u001b[39m     \u001b[38;5;28mself\u001b[39m.command_header +\\\n\u001b[32m   1358\u001b[39m     args_command +\\\n\u001b[32m   1359\u001b[39m     proto.END_COMMAND_PART\n\u001b[32m-> \u001b[39m\u001b[32m1361\u001b[39m answer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgateway_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1362\u001b[39m return_value = get_return_value(\n\u001b[32m   1363\u001b[39m     answer, \u001b[38;5;28mself\u001b[39m.gateway_client, \u001b[38;5;28mself\u001b[39m.target_id, \u001b[38;5;28mself\u001b[39m.name)\n\u001b[32m   1365\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/spark/python/lib/py4j-0.10.9.9-src.zip/py4j/java_gateway.py:1057\u001b[39m, in \u001b[36mGatewayClient.send_command\u001b[39m\u001b[34m(self, command, retry, binary)\u001b[39m\n\u001b[32m   1055\u001b[39m         retry = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   1056\u001b[39m     logging.info(\u001b[33m\"\u001b[39m\u001b[33mException while sending command.\u001b[39m\u001b[33m\"\u001b[39m, exc_info=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m1057\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbinary\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbinary\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1058\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1059\u001b[39m     logging.exception(\n\u001b[32m   1060\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mException while sending command.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/spark/python/lib/py4j-0.10.9.9-src.zip/py4j/java_gateway.py:1036\u001b[39m, in \u001b[36mGatewayClient.send_command\u001b[39m\u001b[34m(self, command, retry, binary)\u001b[39m\n\u001b[32m   1015\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msend_command\u001b[39m(\u001b[38;5;28mself\u001b[39m, command, retry=\u001b[38;5;28;01mTrue\u001b[39;00m, binary=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m   1016\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Sends a command to the JVM. This method is not intended to be\u001b[39;00m\n\u001b[32m   1017\u001b[39m \u001b[33;03m       called directly by Py4J users. It is usually called by\u001b[39;00m\n\u001b[32m   1018\u001b[39m \u001b[33;03m       :class:`JavaMember` instances.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1034\u001b[39m \u001b[33;03m     if `binary` is `True`.\u001b[39;00m\n\u001b[32m   1035\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1036\u001b[39m     connection = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1037\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1038\u001b[39m         response = connection.send_command(command)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/spark/python/lib/py4j-0.10.9.9-src.zip/py4j/clientserver.py:284\u001b[39m, in \u001b[36mJavaClient._get_connection\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    281\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m    283\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m connection.socket \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m284\u001b[39m     connection = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_new_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    285\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m connection\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/spark/python/lib/py4j-0.10.9.9-src.zip/py4j/clientserver.py:291\u001b[39m, in \u001b[36mJavaClient._create_new_connection\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_create_new_connection\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    288\u001b[39m     connection = ClientServerConnection(\n\u001b[32m    289\u001b[39m         \u001b[38;5;28mself\u001b[39m.java_parameters, \u001b[38;5;28mself\u001b[39m.python_parameters,\n\u001b[32m    290\u001b[39m         \u001b[38;5;28mself\u001b[39m.gateway_property, \u001b[38;5;28mself\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m291\u001b[39m     \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect_to_java_server\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    292\u001b[39m     \u001b[38;5;28mself\u001b[39m.set_thread_connection(connection)\n\u001b[32m    293\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m connection\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/spark/python/lib/py4j-0.10.9.9-src.zip/py4j/clientserver.py:438\u001b[39m, in \u001b[36mClientServerConnection.connect_to_java_server\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    435\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ssl_context:\n\u001b[32m    436\u001b[39m     \u001b[38;5;28mself\u001b[39m.socket = \u001b[38;5;28mself\u001b[39m.ssl_context.wrap_socket(\n\u001b[32m    437\u001b[39m         \u001b[38;5;28mself\u001b[39m.socket, server_hostname=\u001b[38;5;28mself\u001b[39m.java_address)\n\u001b[32m--> \u001b[39m\u001b[32m438\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msocket\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mjava_address\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mjava_port\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    439\u001b[39m \u001b[38;5;28mself\u001b[39m.stream = \u001b[38;5;28mself\u001b[39m.socket.makefile(\u001b[33m\"\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    440\u001b[39m \u001b[38;5;28mself\u001b[39m.is_connected = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[31mConnectionRefusedError\u001b[39m: [Errno 111] Connection refused"
     ]
    }
   ],
   "source": [
    "# CUSTOM SCENARIO: Flag suspicious trips\n",
    "print(\"\\n--- Custom Scenario: Flagging Suspicious Trips ---\")\n",
    "\n",
    "trips_with_suspicious = trips_all.withColumn(\n",
    "    \"is_suspicious\",\n",
    "    F.when(\n",
    "        (F.col(\"trip_duration_minutes\") > 120) | \n",
    "        (F.col(\"trip_distance\") > 50) | \n",
    "        (F.col(\"fare_amount\") < 0),\n",
    "        True\n",
    "    ).otherwise(False)\n",
    ")\n",
    "\n",
    "total_trips = trips_with_suspicious.count()\n",
    "suspicious_trips = trips_with_suspicious.filter(F.col(\"is_suspicious\") == True)\n",
    "suspicious_count = suspicious_trips.count()\n",
    "\n",
    "print(f\"Total trips: {total_trips:,}\")\n",
    "print(f\"Suspicious trips found: {suspicious_count:,}\")\n",
    "if total_trips > 0:\n",
    "    print(f\"Percentage: {suspicious_count/total_trips*100:.2f}%\")\n",
    "\n",
    "trips_with_suspicious.write.mode(\"overwrite\").parquet(str(OUT_PATH))\n",
    "print(f\"✓ Main output (with is_suspicious flag) written to: {OUT_PATH}\")\n",
    "\n",
    "SUSPICIOUS_PATH = OUTBOX_PATH / \"suspicious_trips.parquet\"\n",
    "suspicious_trips.write.mode(\"overwrite\").parquet(str(SUSPICIOUS_PATH))\n",
    "print(f\"✓ Suspicious trips written to: {SUSPICIOUS_PATH}\")\n",
    "print(\"--- Custom Scenario Complete ---\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
